hw2
Cifar-10資料集，以CNN卷積式神經網路進行訓練

文件結構(recommended by DeepSeek):
```
cifar10_cnn/
├── data/                # 存放數據集
├── models/              # 保存訓練好的模型
├── utils/               # 工具函數
│   └── preprocess.py    # 數據預處理函數
├── experiments/         # 不同實驗
│   ├── test2_normalization.py
│   ├── test3_shuffle.py
│   └── ...
├── config.py            # 共用配置
└── main.py              # 主入口文件
```

## 測試一：固定模型架構及參數下，資料是否正規化之比較。
![alt text](experiments/normalization_comparison.png)

| 指標                | 未正規化數據 | 正規化數據 | 改善幅度 |
|---------------------|--------------|------------|----------|
| 最終驗證準確率       | 0.62         | 0.68       | +9.7%    |
| 最終驗證損失         | 1.25         | 0.95       | -24%     |
| 收斂所需 epochs      | 6            | 3          | 快 2 倍  |

在CNN訓練中，輸入數據正規化是必要步驟，尤其當像素值範圍較大時(如 0-255)。本測試顯示正規化可同時提升準確率、加速收斂，並降低訓練不穩定性。

## 測試二：固定模型架構及參數下，資料是否進行shuffle之比較。
#### **控制變因**  
- 模型架構(與測試一相同)
- 批次大小(`batch_size=64`)
- Epoch 數(`epochs=10`)
- 優化器與學習率(Adam,預設)  

#### **操縱變因**  
- **有 Shuffle**：`model.fit(shuffle=True)`  
- **無 Shuffle**：`model.fit(shuffle=False)`  
![alt text](experiments/shuffle_comparison.png)

| 指標                | Shuffle=True | Shuffle=False | 差異分析               |
|---------------------|--------------|---------------|------------------------|
| 最終驗證準確率       | 0.68         | 0.62          | +6%                   |
| 最終驗證損失         | 0.95         | 1.15          | -17%                  |
| 訓練穩定性           | 高           | 低（有震盪）   | Shuffle 減少梯度波動   |

測試結果表明，在訓練CNN模型時啟用資料Shuffle能顯著提升模型效能，最終驗證準確率提高約6%，同時使訓練過程更穩定、收斂更快。

## 測試三：固定參數下，卷積層層數多寡之比較。至少三種網路架構，例如：兩層、三層、四層。
- **控制變因**：  
  - 使用相同的優化器（Adam）、學習率、批次大小（batch_size=64）、正規化（像素值縮放到 0-1）  
  - 固定其他層結構（MaxPooling2D、Flatten、Dense）  
- **操縱變因**：  
  - **2層 CNN**：1 Conv+Pool → 1 Conv+Pool → Flatten  
  - **3層 CNN**：1 Conv+Pool → 1 Conv+Pool → 1 Conv（不加 Pool）→ Flatten  
  - **4層 CNN**：1 Conv+Pool → 1 Conv+Pool → 1 Conv（不加 Pool）→ 1 Conv（不加 Pool）→ Flatten  

![alt text](experiments/cnn_layers_comparison.png)
| 模型架構   | 最終驗證準確率 | 最終驗證損失 | 訓練準確率 | 關鍵觀察                     |
|------------|----------------|--------------|------------|------------------------------|
| **2層CNN** | 70.71%         | 0.8879       | 80.30%     | 訓練集過擬合明顯(+9.59%)   |
| **3層CNN** | 73.17%         | 0.9160       | 87.07%     | 最佳泛化能力，但後期波動     |
| **4層CNN** | 73.78%         | 0.8593       | 87.38%     | 最高準確率，但過擬合風險最大 |
- **收斂速度**  
  - 所有模型在Epoch 3-4後驗證準確率趨穩，說明**CIFAR-10在10個Epoch內可達初步收斂**。
  - 4層CNN初期損失下降最快，但後期過擬合。

- **過擬合跡象**  
  - 2層/4層模型的訓練準確率比驗證準確率高出 **10%以上**，3層差距最小(13.9%)。
### 途中問題
  - 輸入圖像尺寸：32x32  
  - 經過 `Conv2D + MaxPooling2D` 兩次後：  
    - 第一次：32x32 → 30x30 (kernel=3x3, padding='valid') → 15x15 (MaxPooling 2x2)  
    - 第二次：15x15 → 13x13 → 6x6  
    - 第三次：6x6 → 4x4 → 2x2  
    - 第四次：2x2 → **無法再進行 3x3 卷積**（因為 2 - 3 + 1 = 0）。  

- **修正後**：  
  - 使用 `padding="same"` 讓卷積層不縮小尺寸（例如 32x32 → 32x32）。  
  - 減少池化層次數，避免特徵圖變得太小。

## 測試四：固定層數、其他參數下，調整filters大小之比較。至少三種數值，例如：16、32、64。
- **控制變因**：  
  - 固定 3 層 CNN 架構（Conv → Pool → Conv → Pool → Conv → Flatten → Dense）  
  - 固定超參數：`epochs=10`, `batch_size=64`, 優化器 (`Adam`), 學習率 (預設值)  
  - 輸入數據正規化 (`x_train/255.0`)  
- **操縱變因**：  
  - 卷積核數量：`filters=[16, 32, 64]`

![alt text](experiments/filters_comparison.png)

| 模型配置       | 最終訓練準確率 | 最終驗證準確率 | 驗證準確率峰值 | 過擬合程度（訓練-驗證差距） |
|----------------|----------------|----------------|----------------|-----------------------------|
| **filters=16** | 83.69%         | 71.85%         | 72.76% (Epoch7)| 11.84%                      |
| **filters=32** | 88.98%         | 72.82%         | 74.24% (Epoch8)| 16.16%                      |
| **filters=64** | 94.80%         | 74.60%         | 74.99% (Epoch9)| 20.20%                      |

- **準確率與容量關係**
   - filters 數量與模型性能呈正相關：
     - 16→32：驗證準確率提升 0.97%
     - 32→64：驗證準確率提升 1.78%
   - filters=64 達到最高驗證準確率 74.6%，但同時伴隨嚴重過擬合（訓練準確率 94.8%）

- **訓練效率對比**
   - 收斂速度：
     - filters=16 最快穩定（Epoch5 達 70%）
     - filters=64 前期收斂快，但後期不穩定
   - 計算成本：
     - filters=64 的每 epoch 時間比 16 多 40%

## 測試五：固定層數、其他參數下，調整kernel_size大小之比較。至少三種數值，例如：(4, 4)、(5, 5)、(7, 7)。

| 控制變因          | 操縱變因               | 評估指標               |
|-------------------|------------------------|------------------------|
| - 3層CNN架構      | kernel_size:           | - 驗證準確率           |
| - filters=32      | - (3,3) [對照組]       | - 驗證損失             |
| - epochs=10       | - (5,5)                | - 訓練穩定性           |
| - batch_size=64   | - (7,7)                | - 過擬合程度           |
| - Adam優化器      |                        | - 計算效率             |

![alt text](experiments/kernel_comparison.png)

- #### **綜合比較**
| kernel_size | 最終驗證準確率 | 峰值驗證準確率 | 最終驗證損失 | 過擬合程度（訓練-驗證差距） | 計算時間/epoch |
|-------------|----------------|----------------|--------------|-----------------------------|----------------|
| **(3,3)**   | 72.88%         | 72.90% (E8)    | 0.9211       | 12.96%                     | ~4.5s          |
| **(5,5)**   | 72.06%         | 72.94% (E8)    | 0.9770       | 15.82%                     | ~5.5s          |
| **(7,7)**   | 67.78%         | 68.21% (E7)    | 1.3539       | 23.15%                     | ~6.0s          |

- **小kernel優勢**：
  - 保留局部細節（如邊緣、紋理）
  - 更適合32x32低解析度圖像
- **大kernel缺陷**：
  - 在淺層網路中，過大感受野導致特徵過度混合
  - 驗證損失後期飆升（(7,7)的E10損失比E1高7.3%）

## 測試六：固定層數、其他參數下，調整pool_size大小之比較。至少三種數值，例如：(2, 2)、(3, 3)、(4, 4)。

| 控制變因          | 操縱變因               | 評估指標               |
|-------------------|------------------------|------------------------|
| - 3層CNN架構      | pool_size:             | - 驗證準確率           |
| - filters=32      | - (2,2) [對照組]       | - 驗證損失             |
| - kernel_size=(3,3)| - (3,3)                | - 特徵保留能力         |
| - epochs=10       | - (4,4)                | - 計算效率             |
| - Adam優化器      |                        | - 過擬合程度           |

![alt text](experiments/pool_comparison.png)

#### **綜合比較**
| pool_size | 最終驗證準確率 | 峰值驗證準確率 | 最終驗證損失 | 訓練-驗證準確率差距 | 計算時間/epoch |
|-----------|----------------|----------------|--------------|----------------------|----------------|
| **(2,2)** | 71.58%         | 73.96% (E9)    | 0.8959       | 13.57%              | ~4.5s          |
| **(3,3)** | 72.56%         | 72.58% (E10)   | 0.8212       | 6.31%               | ~4.8s          |
| **(4,4)** | 68.41%         | 68.41% (E10)   | 0.8983       | 5.61%               | ~5.0s          |

- **準確率與信息保留的權衡**
   - **(2,2) 峰值表現最佳**：Epoch9達73.96%，但後期過擬合明顯（最終71.58%）
   - **(3,3) 最穩定**：驗證準確率持續上升至72.56%，訓練-驗證差距最小（6.31%）
   - **(4,4) 表現最差**：因過度壓縮特徵圖（32x32→2x2），損失空間信息

- **過擬合行為**
   - 大pool_size反而減輕過擬合：
     - (4,4) 的訓練-驗證差距僅5.61%
     - (2,2) 差距達13.57%，因保留過多細節導致記憶訓練集噪聲

- **計算效率**
   - 差異不明顯（<10%），因主要計算量在卷積層